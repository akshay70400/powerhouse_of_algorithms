{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73121037-ef2a-4a86-9c3d-ecefcda8131b",
   "metadata": {},
   "source": [
    "# <mark> <font color='red'> Multichannel Optimization\n",
    "\n",
    "Why needed?\n",
    "\n",
    "    Shift ot digital channels due to cost and hcp preferences\n",
    "    TNN constraints\n",
    "    \n",
    "Solution?\n",
    "\n",
    "    Reccomend optimal resource allocation\n",
    "    Product trust level plans for calls, emails, events\n",
    "    Measure the impact of the optimized plan using A/B testing\n",
    "    \n",
    "Granularity - Bricks sales per month\n",
    "Features - \n",
    "\n",
    "    f2f calls\n",
    "    remote calls\n",
    "    group calls\n",
    "    emails sent\n",
    "    emails viewed\n",
    "    emails clicked\n",
    "    events\n",
    "    newsletter\n",
    "    hcp consent calls\n",
    "    hcp consent emails\n",
    "    is key opinion leader\n",
    "    product segment - A B C D\n",
    "    \n",
    "Data?\n",
    "\n",
    "    2 years\n",
    "    brick level sales data\n",
    "    segments of customers\n",
    "        product segment \n",
    "            - used for modelling of pol eyl\n",
    "            - A, B, C, D, E\n",
    "        behaviour segment \n",
    "            - used for modelling of fra xrlt\n",
    "            - \n",
    "        adoption(current) segment\n",
    "        adoption(long term) segment\n",
    "            - prescriber\n",
    "            - referer\n",
    "            - Key opinion leader\n",
    "        potential segment\n",
    "            - 1, 2, 3, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd22d9c-2541-416e-a859-fd09b5cb1d5b",
   "metadata": {},
   "source": [
    "Brands\n",
    "\n",
    "    eylea - treating eyes\n",
    "    xeralto - prevent blood clots\n",
    "    nubeca - treat prostate cancer\n",
    "    whc - whc products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d3c00-da84-4958-9616-60597c916d0b",
   "metadata": {},
   "source": [
    "## <font color='red'> APPROACH 1: pol eyl which is having less number of customers 970 customers thus sparse data, need of more explainable linear model.\n",
    "\n",
    "`1. Linear model`\n",
    "\n",
    "Linear OLS model was fit on data to find out the impact of marketing activities on sales of the product. This would give us the weights of each channel as an impact measure on the sales.\n",
    "    \n",
    "    Models used and tried:\n",
    "        constrained old (with positive coefficients only)\n",
    "        regular ols ()\n",
    "        mixed model (with random effects for area)\n",
    "    Trend/seasonlity was removed from the marketing signals to better capture the effect of marketing activities only\n",
    "    trend/seasonality due to covid were clearly visible.\n",
    "    \n",
    "    STAGE 1:\n",
    "        TARGET: normalized sales four months in future\n",
    "        FEATURES: month, bricks, covid terms\n",
    "        This will filter out the NON-MAKRTING SIGNALS and the error terms would represent the marketing signals\n",
    "    STAGE 2:    \n",
    "        TARGET: normalized sales four months in future\n",
    "        FEATURES: marketing activities\n",
    "        fitting the touchpoint features on error terms of stage 1 to get the importance of features.\n",
    "\n",
    "`2. PuLP optimization (weights of each touchpoint feature to be obtained from the stage 1)`\n",
    "    \n",
    "    segment used - product segment\n",
    "    minimize: marketing expenses: Z = w1 * calls + w2 * emails + w3 * events\n",
    "    subject to:\n",
    "        number of calls <= 100\n",
    "        number of emails <= 100\n",
    "        number of events <= 100\n",
    "        calls expense <= 900\n",
    "        emails expense <= 500\n",
    "        events expense <= 1500\n",
    "        calls cost, emails cost, event cost = 20, 5, 100\n",
    "        WEIGHTS FOR EACH TOUCHPOINT WERE BASED ON THE two stage model developed earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01f3d6a-aef0-4746-8db5-7f17e74a3c15",
   "metadata": {},
   "source": [
    "## <font color='red'> APPROACH 2: fra xrlt, gbr xrlt\n",
    "\n",
    "`1. XGboost model + shapely to get the IMPACT ATTRIBUTION OF EACH feature`\n",
    "    \n",
    "\n",
    "`2. PSO: Top 10 features/touchpoints optimized using PSO`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e17358d-a46f-49ad-a82f-4f94a717ccc5",
   "metadata": {},
   "source": [
    "# <font color='red'> model input table\n",
    "\n",
    "granularity of sales per brick per month was used\n",
    "    \n",
    "    \n",
    "    brick_id | observation_dt | \n",
    "    \n",
    "    features (4 month lag varibales for each touchpoint were used) (lag can be customized as per country_brand)\n",
    "        \n",
    "        f2f_A_nrm_4 *****\n",
    "        f2f_B_nrm_4\n",
    "        f2f_C_nrm_4\n",
    "        f2f_D_nrm_4\n",
    "        remote_A_nrm_4\n",
    "        remote_B_nrm_4 *****\n",
    "        remote_C_nrm_4\n",
    "        remote_D_nrm_4\n",
    "        group_A_nrm_4\n",
    "        group_B_nrm_4\n",
    "        group_C_nrm_4\n",
    "        group_D_nrm_4 *****\n",
    "        emails_sent_nrm_4_A\n",
    "        emails_sent_nrm_4_B\n",
    "        emails_sent_nrm_4_C\n",
    "        emails_sent_nrm_4_D\n",
    "        emails_clicked_nrm_4_A\n",
    "        emails_clicked_nrm_4_B\n",
    "        emails_clicked_nrm_4_C\n",
    "        emails_clicked_nrm_4_D\n",
    "        event_nrm_4_A\n",
    "        event_nrm_4_B \n",
    "        event_nrm_4_C *****\n",
    "        event_nrm_4_D *****\n",
    "    \n",
    "    target \n",
    "        \n",
    "        (normalized eylea sales in last 3 months/ 4 months)\n",
    "        market_share_eyl_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06064c9-b2a0-465d-a8fc-d0af5d2b7915",
   "metadata": {},
   "source": [
    "# <font color='red'> TABLES INFORMATION\n",
    "\n",
    "ACCOUNT TABLE\n",
    "       \n",
    "    acct_id\n",
    "    acc_name\n",
    "    gender\n",
    "    is_doctor\n",
    "    is_prescriber\n",
    "    is_professor\n",
    "    brick\n",
    "    country\n",
    "    is_key_opinion_leader\n",
    "    is_influencer\n",
    "    accnt_speciality\n",
    "    accnt_secondary_speciality\n",
    "    accnt_tertiary_speciality\n",
    "    record_type\n",
    "\n",
    "CHILD ACCOUNT\n",
    "\n",
    "ADDRESS TABLE\n",
    "    \n",
    "    country\n",
    "    region\n",
    "    brick\n",
    "\n",
    "CALLS TABLE\n",
    "        \n",
    "    who made call\n",
    "    f2f? remote? group?\n",
    "    date\n",
    "    call duration\n",
    "\n",
    "CALL2 DETAILS\n",
    "\n",
    "EMAILS\n",
    "    \n",
    "    sent_timestamp\n",
    "    product marketed\n",
    "    email content\n",
    "    headline\n",
    "    \n",
    "\n",
    "EVENTS\n",
    "\n",
    "SUGGESTIONS\n",
    "\n",
    "USER TABLE\n",
    "\n",
    "    information about the user/sales representatives who contact hcps\n",
    "\n",
    "PRODUCT TABLE\n",
    "\n",
    "GLOBAL SEGMENTS TABLE\n",
    "    \n",
    "        product segment \n",
    "            - used for modelling of pol eyl\n",
    "            - A, B, C, D, E\n",
    "        behaviour segment \n",
    "            - used for modelling of fra xrlt\n",
    "            - \n",
    "        adoption(current) segment\n",
    "        adoption(long term) segment\n",
    "            - prescriber\n",
    "            - referer\n",
    "            - Key opinion leader\n",
    "            - influencer\n",
    "        potential segment\n",
    "            - 1, 2, 3, 4\n",
    "\n",
    "MULTICHANNEL CONSENT TABLE\n",
    "\n",
    "MULTICHANNEL CYCLE PLAN TABLE\n",
    "    \n",
    "IQVIA SALES\n",
    "    \n",
    "    brick level\n",
    "    trust level\n",
    "    pharmaceutical level\n",
    "    country level\n",
    "    drug_amt\n",
    "    eyl vs competitor's sales data: - this helped get the market share of eyl drug per brick during that month.\n",
    "    \n",
    "XFACTORY SALES\n",
    "    \n",
    "    xfactory data, drugs sold at xfactory level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc41034c-c1e1-45c6-9f8a-ada1db68d372",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4d38ba2-7679-41f6-a265-f6e918812757",
   "metadata": {},
   "source": [
    "# <mark> <font color='red'> EMAIL HEADLINER\n",
    "    \n",
    "Problem?\n",
    "    \n",
    "    Per product per customer/hcp (for different segments of customers) what keywords should be mainteained in the email headline and content for the best click though rate.\n",
    "    \n",
    "Solution?\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be41831-cc04-4d1b-9be7-77557f24390b",
   "metadata": {},
   "source": [
    "# <mark> <font color='red'> MICRO SEGMENTATION\n",
    "    \n",
    "Problem?\n",
    "    \n",
    "    To find out and cluster most important customers per country brand per segment and devise the necessary marketing stratergy for better targetting of customers.\n",
    "    \n",
    "Solution?\n",
    "    \n",
    "    K-Means algorithm was used to segment the customers.\n",
    "    Data:\n",
    "        3 years\n",
    "        2 lakh records\n",
    "        granularity: hcp\n",
    "        features represented hcp behaviour, potential, segment, prescrition data, consent inforamtion, earlier touchpoints(calls, emails, events) to that customer\n",
    "    Model explainability was important.\n",
    "    Clusters found = 12, grouped into 4 classes as per segmentation policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49777d3-482b-452e-bb83-109830956c30",
   "metadata": {},
   "source": [
    "# <mark> <font color='red'> IMPACT ATTRIBUTION\n",
    "    \n",
    "Problem?\n",
    "    \n",
    "    To find out and assing the weightages to each marketing activity towards their contribution of sales.\n",
    "    Ex. How much last three month's calls/emails/events have contributed to sales in that brick.\n",
    "    \n",
    "Solution?\n",
    "    \n",
    "    XG boost algorithm\n",
    "    Shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5794b76-c041-4e99-b1ec-c359a25366e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <mark> <font color='red'> DATA PIPELINES USING KEDRO\n",
    "    \n",
    "    Raw layer\n",
    "        Basic cleaning\n",
    "    Intermediate layer\n",
    "        Column renaming, removing unwanted data, etc\n",
    "    Primary layer\n",
    "        Joining of tables\n",
    "    Feature layer\n",
    "        comm_crm\n",
    "        comm_sales\n",
    "        normalized and aggregated features\n",
    "        normalized by number of hcps per segment\n",
    "        pivoted features based on a particular column of interest.\n",
    "    Model input layer\n",
    "        mod_clustering\n",
    "        mod_brick_sales\n",
    "        mod_trust_sales\n",
    "        mod_impact_attribution\n",
    "    Usecase layer\n",
    "        multichannel optimization\n",
    "        microsegmtation\n",
    "        impact attribution\n",
    "        suggestion engines\n",
    "---------------------------------------------------------\n",
    "    Kedro Framework:\n",
    "        Connectors\n",
    "        Catalog\n",
    "        Nodes\n",
    "        Parameters\n",
    "        Piplines\n",
    "    Advantages:\n",
    "        Modular code\n",
    "        Maintainance and debugging was easy\n",
    "    \n",
    "\n",
    "Kedro offers a way to package the code to make the pipelines callable, but does not manage specifically machine learning models. Mlflow offers a way to store machine learning models with a given “flavor”, which is the minimal amount of information necessary to use the model for prediction: a configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58188d36-0553-4dcb-ba20-95f2b518a48d",
   "metadata": {
    "tags": []
   },
   "source": [
    "https://github.com/kedro-org/kedro\n",
    "\n",
    "### Features of Kedro:\n",
    "\n",
    "    Kedro is a toolbox for production-ready data science. \n",
    "    \n",
    "    It uses software engineering best practices to help you create data engineering and data science pipelines that are `REPRODUCIBLE, MODULAR & MAINTAINABLE.`\n",
    "\n",
    "    Open Source\n",
    "    A standard, modifiable and easy-to-use project template.\n",
    "    Create separate Data Engineering and Data Science pipelines thus helps collaborate DEs and DSts together.\n",
    "    \n",
    "    Catalog\n",
    "        A series of lightweight data connectors used to save and load data across many different file formats and file systems, including local and network file systems, cloud object stores, and HDFS. The Data Catalog also includes data and model versioning for file-based systems.\n",
    "        \n",
    "    nodes.py (for the node functions that form the data processing)\n",
    "    \n",
    "    pipeline.py (to build the pipeline)\n",
    "    \n",
    "    parameters.yml : A yaml file: conf/base/parameters/data_processing.yml to define the parameters used when running the pipeline\n",
    "\n",
    "    Pipeline Abstraction\n",
    "\n",
    "    Automatic resolution of dependencies between pure Python functions and data pipeline visualisation using Kedro-Viz.\n",
    "\n",
    "    Coding Standards\n",
    "\n",
    "    Test-driven development using pytest, produce well-documented code using Sphinx, create linted code with support for flake8, isort and black and make use of the standard Python logging library.\n",
    "    \n",
    "    Flexible Deployment: Deployment strategies that include single or distributed-machine deployment as well as additional support for deploying on Argo, Prefect, Kubeflow, AWS Batch and Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0709de4b-a624-4a38-8736-3b7a8870ae81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2387a9d-d688-4230-b0bc-a2cefb2a2938",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
